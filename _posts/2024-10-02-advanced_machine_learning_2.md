---
title: "[KT AIVLE] λ¨Έμ‹ λ¬λ‹ 4μΌμ°¨ - μ‹¬ν™”ν•™μµ"
description: 
author:
date: 2024-10-02 21:00:00 +0900
categories: [KT aivle school, λ¨Έμ‹ λ¬λ‹]
tags: [KT aivle school]
pin: false
math: true
mermaid: true
image:
  # path: /assets/img/20240912_post/KT_λ¨μ§‘μ”κ°•.jpg
  # lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
  # alt: ktaivel_image
---


## **0. κ°μ”**
<hr style="height: 0.5px; background-color: rgba(0, 0, 0, .1); border: none;" /> 
μ›λ μ£Όκ°„λ‚΄μ©μΌλ΅ μ •λ¦¬ν•μ§€λ§ ν•΄λ‹Ήλ‚΄μ©μ€ μ£Όκ°„ μ •λ¦¬λ΅λ§ λ‹΄κΈ°μ—λ” ν•κ³„κ°€ μμ–΄ μ‹¬ν™”ν•™μµ λ‚΄μ©μ„ μ¶”κ°€μ μΌλ΅ μ •λ¦¬ν•κ³ μ ν•©λ‹λ‹¤.

<br/>

## **1. λ¨Έμ‹ λ¬λ‹**
<hr style="height: 0.5px; background-color: rgba(0, 0, 0, .1); border: none;" /> 
μ΄μ–΄μ„ κΈ°λ³Έ μ•κ³ λ¦¬μ¦ μ •λ¦¬λ¶€ν„° μ‹μ‘ν•λ„λ΅ ν•κ² μµλ‹λ‹¤.

<br/>

## **2. κΈ°λ³Έ μ•κ³ λ¦¬μ¦**
<hr style="height: 0.5px; background-color: rgba(0, 0, 0, .1); border: none;" />

### **2.4 ) Logistic Regression(λ¶„λ¥λ¨λΈλ§ κ°€λ¥)**
- λ΅μ§€μ¤ν‹± ν•¨μ
![Desktop View](/assets/img/20241002_post/logistic_fun.JPG){: width="800" height="400"}
  - μ‹κ·Έλ¨μ΄λ“ ν•¨μλΌκ³ λ„ λ¶€λ¦„
  - ν™•λ¥  κ°’ π‘ λ” μ„ ν• νλ³„μ‹ κ°’μ΄ μ»¤μ§€λ©΄ 1, μ‘μ•„μ§€λ©΄ 0μ— κ°€κΉμ΄ κ°’μ΄ λ¨
  - (-β, β) λ²”μ„λ¥Ό κ°–λ” μ„ ν• νλ³„μ‹ κ²°κ³Όλ΅ (0, 1) λ²”μ„μ ν™•λ¥  κ°’μ„ μ–»κ² λ¨
  - κΈ°λ³Έμ μΌλ΅ ν™•λ¥  κ°’ 0.5λ¥Ό μ„κ³„κ°’(Threshold)λ΅ ν•μ—¬ μ΄λ³΄λ‹¤ ν¬λ©΄ 1, μ•„λ‹λ©΄ 0μΌλ΅ λ¶„λ¥ν•¨   
> π‘¥ λ°μ΄ν„°κ°€ μ£Όμ–΄μ΅μ„ λ• ν™•λ¥ μ„ μμΈ΅ν•λ” λ΅μ§€μ¤ν‹± νκ·€λ¶„μ„μ€ ν•™μµ λ°μ΄ν„°λ¥Ό μ μ„¤λ…ν•λ” μ„ ν• νλ³„μ‹μ κΈ°μΈκΈ°(π‘)μ™€ μ νΈ(π‘)μ„ μ°Ύλ” λ¬Έμ 
- λ¨λΈ κµ¬ν„
```python
# λ¶λ¬μ¤κΈ°
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report
# μ„ μ–Έν•κΈ°
model = LogisticRegression()
# ν•™μµν•κΈ°
model.fit(x_train, y_train)
# μμΈ΅ν•κΈ°
y_pred = model.predict(x_test)
# ν‰κ°€ν•κΈ°
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
```

<br/>

## **3. K-Fold Cross Validation**
<hr style="height: 0.5px; background-color: rgba(0, 0, 0, .1); border: none;" />

- Random splitμ λ¬Έμ 
  - μƒλ΅μ΄ λ°μ΄ν„°μ— λ€ν• λ¨λΈμ μ„±λ¥μ„ μμΈ΅ν•μ§€ λ»ν• μƒνƒμ—μ„ μµμΆ… ν‰κ°€λ¥Ό μν–‰
  - κ²€μ¦μ© λ°μ΄ν„°κ°€ λ¨λΈμ μΌλ°ν™”λ μ„±λ¥μ„ μμΈ΅ν•  μ μκ² λ„μ™€ μ£ΌκΈ°λ” ν•μ§€λ§ λ”μ± μ •κµν• ν‰κ°€ μ μ°¨κ°€ ν•„μ”ν•¨
![Desktop View](/assets/img/20241002_post/random_split.JPG){: width="800" height="400"}

### K-λ¶„ν•  κµμ°¨κ²€μ¦
- λ¨λ“  λ°μ΄ν„°κ°€ ν‰κ°€μ— ν•λ², ν•™μµμ— k-1λ² μ‚¬μ©(λ‹¨, kλ” 2 μ΄μƒμ΄ λμ–΄μ•Ό ν•¨(μµμ†ν• ν• κ°μ”©μ ν•™μµμ©, κ²€μ¦μ© λ°μ΄ν„°κ°€ ν•„μ”))
- Kκ°μ λ¶„ν• (Fold)μ— λ€ν• μ„±λ¥μ„ μμΈ΅ β†’ ν‰κ· κ³Ό ν‘μ¤€νΈμ°¨ κ³„μ‚° β†’ μΌλ°ν™” μ„±λ¥
![Desktop View](/assets/img/20241002_post/k_fold_cross.JPG){: width="800" height="400"}
- μ¥λ‹¨μ 
  - μ¥μ 
    - λ¨λ“  λ°μ΄ν„°λ¥Ό ν•™μµκ³Ό ν‰κ°€μ— μ‚¬μ©ν•  μ μμ
    - λ°λ³µ ν•™μµκ³Ό ν‰κ°€λ¥Ό ν†µν•΄ μ •ν™•λ„λ¥Ό ν–¥μƒμ‹ν‚¬ μ μμ
    - λ°μ΄ν„°κ°€ λ¶€μ΅±ν•΄μ„ λ°μƒν•λ” κ³Όμ†μ ν•© λ¬Έμ λ¥Ό λ°©μ§€ν•  μ μμ
    - ν‰κ°€μ— μ‚¬μ©λλ” λ°μ΄ν„°μ νΈν–¥μ„ λ§‰μ„ μ μμ
    - μΆ€ λ” μΌλ°ν™”λ λ¨λΈμ„ λ§λ“¤ μ μμ
  - λ‹¨μ 
    - λ°λ³µ νμκ°€ λ§μ•„μ„ λ¨λΈ ν•™μµκ³Ό ν‰κ°€μ— λ§μ€ μ‹κ°„μ΄ μ†μ”λ¨
- K-λ¶„ν•  κµμ°¨κ²€μ¦ μ‚¬μ©λ°©λ²•
  - λ¨λΈ μ„ μ–Έ ν›„ cross_val_score(λ¨λΈ, x_train, y_train, λ¶„ν•  κ°μ)
  - κΈ°λ³Έ λ¶„ν•  κ°μ(cv) κ°’μ€ 5μ΄λ©°, ν•„μ”μ— λ”°λΌ μ μ ν μ΅°μ 
  - cross_val_score ν•¨μ κ²°κ³Όλ΅ μ–»μ€ μ„±λ¥λ“¤μ ν‰κ· μ„ λ¨λΈμ μ„±λ¥μΌλ΅ λ΄„
  - λ¬Όλ΅  μ‹¤μ  ν‰κ°€μ—μ„ μ–»μ€ μ„±λ¥μ΄ μ΄ μ„±λ¥λ³΄λ‹¤ λ” λ†’κ±°λ‚ λ‚®μ„ μ μμ
```python
# 1λ‹¨κ³„: λ¶λ¬μ¤κΈ°
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
# 2λ‹¨κ³„: μ„ μ–Έν•κΈ°
model = DecisionTreeClassifier(max_depth=3)
# 3λ‹¨κ³„: κ²€μ¦ν•κΈ°
cv_score = cross_val_score(model, x_train, y_train, cv=10)
# ν™•μΈ
print(cv_score)
print(cv_score.mean())
```

<br/>

## **4. Hyperparameter νλ‹**
<hr style="height: 0.5px; background-color: rgba(0, 0, 0, .1); border: none;" />

### Hyperparameter
- μ•κ³ λ¦¬μ¦μ„ μ‚¬μ©ν•΄ λ¨λΈλ§ν•  λ• λ¨λΈ μ„±λ¥μ„ μµμ ν™”ν•κΈ° μ„ν•΄ μ΅°μ ν•  μ μλ” λ§¤κ°λ³€μ
- νλ‹ν•λ” λ°©λ²•μ€ μ§€μ‹κ³Ό κ²½ν—...κ·Έλ¦¬κ³  λ¬΄ν• try
- λ‹¤μ–‘ν• μ‹λ„ λ°©λ²•
  - Grid Search
  - Random Search
- KNN
  - k κ°’μ΄ κ°€μ¥ ν΄ λ•(=μ „μ²΄ λ°μ΄ν„° κ°μ) κ°€μ¥ λ‹¨μ λ¨λΈ -> ν‰κ· , μµλΉκ°’μ— κ·Όμ‚¬ν•΄μ§
  - k κ°’μ΄ μ‘μ„ μλ΅ λ³µμ΅ν• λ¨λΈ
  - κ±°λ¦¬ κ³„μ‚°λ²•(metric)μ— λ”°λΌ μ„±λ¥μ΄ λ‹¬λΌμ§ μ μμ(μ ν΄λ¦¬λ“, λ§¨ν•νΌ)
- Decision Tree(μ΄ λ¨λΈμ€ κ³Όμ ν•©μΌλ΅ μ λ…ν•¨)
  - max_depth
    - μ΄ κ°’μ΄ μ‘μ„ μλ΅ νΈλ¦¬ κΉμ΄κ°€ μ–•μ•„μ € λ¨λΈμ΄ λ‹¨μν•΄μ§
  - min_samples_leaf
    - leafκ°€ λκΈ° μ„ν• μµμ†ν•μ μƒν” λ°μ΄ν„° μ
    - μ΄ κ°’μ΄ ν΄ μλ΅ λ¨λΈμ΄ λ‹¨μν•΄ μ§
  - min_samples_split
    - λ…Έλ“λ¥Ό λ¶„ν• ν•κΈ° μ„ν• μµμ†ν•μ μƒν” λ°μ΄ν„° μ
    - μ΄ κ°’μ΄ ν΄ μλ΅ λ¨λΈμ΄ λ‹¨μν•΄ μ§

### Random Search, Grid Search
- νλΌλ―Έν„° κ°’μ— λ€ν• κ³ λ―Ό(λ­κ°€ μµμ„ μΌκΉ? μΌμΌν λ‹¤ ν•΄λ΄μ•Όν•λ”κ±ΈκΉ?)
  - μ΄λ¥Ό μ„ν•΄ λ“±μ¥ν• Random Search, Grid Search
  - Grid Search
    - μ„±λ¥μ„ ν…μ¤νΈν•  νλΌλ―Έν„° κ°’μ λ²”μ„λ¥Ό μ§€μ •(λ”•μ…”λ„λ¦¬ ν•νƒ)
    - νλΌλ―Έν„° κ°’ λ²”μ„λ¥Ό λ¨λ‘ μ‚¬μ©ν•λ” Grid Search λ¨λΈ μ„ μ–Έ ν›„ ν•™μµ
    - κ°€μ¥ μΆ‹μ€ μ„±λ¥μ„ λ³΄μΈ νλΌλ―Έν„° κ°’μΌλ΅ μλ™μΌλ΅ ν•™μµ
  - Random Search
    - μ„±λ¥μ„ ν…μ¤νΈν•  νλΌλ―Έν„° κ°’μ λ²”μ„λ¥Ό μ§€μ •(λ”•μ…”λ„λ¦¬ ν•νƒ)
    - νλΌλ―Έν„° κ°’ λ²”μ„μ—μ„ λ‡ κ° μ„ νƒν•  μ§€ μ •ν•μ—¬ Random Search λ¨λΈ μ„ μ–Έ ν›„ ν•™μµ
    - κ°€μ¥ μΆ‹μ€ μ„±λ¥μ„ λ³΄μΈ νλΌλ―Έν„° κ°’μΌλ΅ μλ™μΌλ΅ ν•™μµ
  - λ”•μ…”λ„λ¦¬ ν•νƒλ΅ νλΌλ―Έν„° λ²”μ„ μ§€μ •
```python
# νλΌλ―Έν„° ν•λ‚μ κ²½μ°
param = {'n_neighbors': range(1, 101)}
# νλΌλ―Έν„° λ‘ κ° κ²½μ°
param = {'n_neighbors': range(1, 101), 
'metric': ['euclidean', 'manhattan']}
```
- Random Search μ‚¬μ© λ²•
  1. ν•¨μ λ¶λ¬μ¤κΈ°
```python
# ν•¨μ λ¶λ¬μ¤κΈ°
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import RandomizedSearchCV
```
  2. νλ¦¬λ―Έν„° κ°’ λ²”μ„ μ§€μ •
    - λ”•μ…”λ„λ¦¬λ΅ κ°’ λ²”μ„ μ§€μ •
    - λ―Έμ§€μ • νλΌλ―Έν„° κ°’μ€ κΈ°λ³Έκ°’μΌλ΅ μ§€μ •λ¨
    - λ¦¬μ¤νΈ ν•νƒ λλ” range() ν•¨μ λ“±μ„ μ‚¬μ©ν•΄ μ μ ν• step μ„¤μ •
```python
# νλΌλ―Έν„° μ„ μ–Έ
param = {'n_neighbors': range(1, 500, 10), 
'metric': ['euclidean', 'manhattan']}
```
  3. λ¨λΈ μ„ μ–Έ
    - κΈ°λ³Έ λ¨λΈ μ„ μ–Έ
    - Random Search λ¨λΈ μ„ μ–Έ
    - n_iterμ— μν–‰ νμ / (μ„μλ΅ μ„ νƒν•  νλΌλ―Έν„° μ΅°ν•© μ) μ§€μ •
    - μ μ ν• cv κ°’ μ§€μ •
```python
# κΈ°λ³Έλ¨λΈ μ„ μ–Έ
knn_model = KNeighborsClassifier()
# Random Search μ„ μ–Έ
model = RandomizedSearchCV(knn_model,
param,
cv=3, 
n_iter=20)
```
  4. λ¨λΈ ν•™μµ
    - κΈ°λ³Έ λ¨λΈμ΄ μ•„λ‹λΌ Random Search λ¨λΈ ν•™μµ
    - λ¨λΈ ν•™μµ κ³Όμ •μ΄ μµμ„ μ νλΌλ―Έν„° κ°’μ„ μ°Ύλ” κ³Όμ •
    - κ²½μ°μ— λ”°λΌ λ§μ€ μ‹κ°„μ΄ μ†μ” λ  μ μμ
```python
# ν•™μµν•κΈ°
model.fit(x_train, y_train)
```
  5. κ²°κ³Ό ν™•μΈ
    - ν•™μµ κ²°κ³Όλ¥Ό μ—΄μ–΄λ³΄λ©΄ λ”•μ…”λ„λ¦¬ ν•νƒ
```python
# μν–‰ μ •λ³΄
model.cv_results_
# μµμ  νλΌλ―Έν„°
model.best_params_
# μµκ³  μ„±λ¥
model.best_score_
```
  6. μμΈ΅ λ° ν‰κ°€
    - μµμ„ μ νλΌλ―Έν„° κ°’μΌλ΅ λ¨λΈμ΄ μλ™μΌλ΅ ν•™μµλ μƒνƒ

- Grid Search μ‚¬μ© λ²•
  - λ‹¤μ μ‚¬ν•­μ„ μ°Έκ³ ν•΄ Random Searchμ™€ κ°™μ€ κ³Όμ •μΌλ΅ μ§„ν–‰
    - ν•¨μκ°€ λ‹¤λ¦„: GridSearchCV
    - n_iter μµμ…μ„ μ§€μ •ν•μ§€ μ•μ
    - λ„“μ€ λ²”μ„μ™€ ν° StepμΌλ΅ μ„¤μ •ν• ν›„ λ²”μ„λ¥Ό μΆν€ λ‚κ°€λ” λ°©μ‹μΌλ΅ μ‹κ°„μ„ λ‹¨
```python
# ν•¨μ λ¶λ¬μ¤κΈ°
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
# νλΌλ―Έν„° μ„ μ–Έ
param = {'n_neighbors': range(1, 500, 10), 'metric': ['euclidean', 'manhattan']}
# κΈ°λ³Έλ¨λΈ μ„ μ–Έ
knn_model = KNeighborsClassifier()
# Grid Search μ„ μ–Έ
model = GridSearchCV(knn_model, param, cv=3)
```

- λ³΄λ‹¤ μ •ν™•λ„ λ†’κ² μμΈ΅ν•λ ¤λ©΄?
  - Random Search + Grid Search μ μ© κ³ λ ¤
    - Random Searchλ΅ κ°€μ¥ λ†’μ€ κ°’μ„ μ°Ύμ€λ‹¤μ Grid Searchλ¥Ό ν†µν•΄ μΈκ·Όκ°’μ¤‘ μµκ³ κ°’μ„ μ„ μ •

<br/>

## **5. μ‹¤μµ μ½”λ“**
λ¨Έμ‹ λ¬λ‹ λν• μ‹¤μµ μ„μ£Όλ΅ μ§„ν–‰ν•μ€μΌλ©° μ½”λ“λ” gitμ— μ—…λ΅λ“ ν•μ€μµλ‹λ‹¤.  
[μ‹¤μµμ½”λ“](https://github.com/Lucky-SeoYounghyun/kt_aivle/tree/main/ML/2024.09.26)